{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for NN with Artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for generating datasets from Gaussian mixtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mix(m1,m2,m3,cov,n_samples):\n",
    "    n_samples=int(n_samples/3)\n",
    "    x, y = np.random.multivariate_normal(m1, cov, n_samples).T\n",
    "    x=x.reshape((n_samples,1))\n",
    "    y=y.reshape((n_samples,1))\n",
    "    data1=np.hstack((x,y))\n",
    "    x, y = np.random.multivariate_normal(m2, cov, n_samples).T\n",
    "    x=x.reshape((n_samples,1))\n",
    "    y=y.reshape((n_samples,1))\n",
    "    data2=np.hstack((x,y))\n",
    "    x, y = np.random.multivariate_normal(m3, cov, n_samples).T\n",
    "    x=x.reshape((n_samples,1))\n",
    "    y=y.reshape((n_samples,1))\n",
    "    data3=np.hstack((x,y))\n",
    "    data=np.vstack((data1,data2,data3))\n",
    "    np.random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of data from the central distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is unsliceable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-6c462c02e8e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m/=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.multivariate_normal\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is unsliceable"
     ]
    }
   ],
   "source": [
    "n_samples=4000\n",
    "n_samples/=4\n",
    "x, y = np.random.multivariate_normal(m1, cov, n_samples).T\n",
    "x=x.reshape((n_samples,1))\n",
    "y=y.reshape((n_samples,1))\n",
    "data1=np.hstack((x,y))\n",
    "x, y = np.random.multivariate_normal(m2, cov, n_samples).T\n",
    "x=x.reshape((n_samples,1))\n",
    "y=y.reshape((n_samples,1))\n",
    "data2=np.hstack((x,y))\n",
    "x, y = np.random.multivariate_normal(m3, cov, n_samples).T\n",
    "x=x.reshape((n_samples,1))\n",
    "y=y.reshape((n_samples,1))\n",
    "data3=np.hstack((x,y))\n",
    "x, y = np.random.multivariate_normal(m4, cov, n_samples).T\n",
    "x=x.reshape((n_samples,1))\n",
    "y=y.reshape((n_samples,1))\n",
    "data4=np.hstack((x,y))\n",
    "data=np.vstack((data1,data2,data3,data4))\n",
    "np.random.shuffle(data)\n",
    "test=data\n",
    "labels = np.sign(test[:,0]*test[:,1]).reshape((test.shape[0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning labels to the central distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab=np.zeros((len(labels),2))\n",
    "for i in range(len(labels)):\n",
    "    if labels[i]==-1:\n",
    "        lab[i][0]=1\n",
    "    else:\n",
    "        lab[i][1]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of individual classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in our dataset is: 5400\n"
     ]
    }
   ],
   "source": [
    "m1=np.array([1,1])\n",
    "m2=np.array([-1,1])\n",
    "m3=np.array([-1,-1])\n",
    "m4=np.array([1,-1])\n",
    "cov=[[1,0],[0,1]]\n",
    "X1 = gaussian_mix(m1,m2,m3,cov,5400)\n",
    "y1 = np.sign(X1[:,0]*X1[:,1]).reshape((5400,1))\n",
    "\n",
    "X2 = gaussian_mix(m1,m3,m4,cov,5400)\n",
    "y2 = np.sign(X1[:,0]*X1[:,1]).reshape((5400,1))\n",
    "\n",
    "print(\"Total samples in our dataset is: {}\".format(X1.shape[0]))\n",
    "n_samples = len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "val=np.zeros((len(y1),2))\n",
    "for i in range(len(y1)):\n",
    "    if y1[i]==-1:\n",
    "        val[i][0]=1\n",
    "    else:\n",
    "        val[i][1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X1, val, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0,X)\n",
    "\n",
    "def reluD(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 56.07%\n"
     ]
    }
   ],
   "source": [
    "w0 = 2*np.random.random((2, 20)) - 1\n",
    "w1 = 2*np.random.random((20, 2)) - 1\n",
    "n=0.01\n",
    "for i in range(100000):\n",
    "    layer0 = x_train\n",
    "    layer1 = relu(np.dot(layer0, w0))\n",
    "    layer2 = sigmoid(np.dot(layer1, w1))\n",
    "    layer2_error = y_train - layer2\n",
    "    layer2_delta = layer2_error * sigmoid_deriv(layer2)\n",
    "    layer1_error = layer2_delta.dot(w1.T)\n",
    "    layer1_delta = layer1_error * reluD(layer1)\n",
    "    w1 += layer1.T.dot(layer2_delta) * n\n",
    "    w0 += layer0.T.dot(layer1_delta) * n\n",
    "    error = np.mean(np.abs(layer2_error))\n",
    "    accuracy = (1 - error) * 100\n",
    "print(\"Training Accuracy \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 57.38%\n"
     ]
    }
   ],
   "source": [
    "layer0 = x_test\n",
    "layer1 = relu(np.dot(layer0, w0))\n",
    "layer2 = sigmoid(np.dot(layer1, w1))\n",
    "layer2_error = y_test - layer2\n",
    "error = np.mean(np.abs(layer2_error))\n",
    "accuracy = (1 - error) * 100\n",
    "\n",
    "print(\"Test Accuracy \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 56.57%\n"
     ]
    }
   ],
   "source": [
    "val2=np.zeros((len(y2),2))\n",
    "for i in range(len(y2)):\n",
    "    if y2[i]==-1:\n",
    "        val2[i][0]=1\n",
    "    else:\n",
    "        val2[i][1]=1        \n",
    "x_train, x_test, y_train, y_test = train_test_split(X2, val2, test_size=0.33, random_state=0)\n",
    "w02 = 2*np.random.random((2, 20)) - 1\n",
    "w12 = 2*np.random.random((20, 2)) - 1\n",
    "n=0.01\n",
    "for i in range(100000):\n",
    "    layer02 = x_train\n",
    "    layer12 = sigmoid(np.dot(layer02, w02))\n",
    "    layer22 = sigmoid(np.dot(layer12, w12))\n",
    "    layer22_error = y_train - layer22\n",
    "    layer22_delta = layer22_error * sigmoid_deriv(layer22)    \n",
    "    layer12_error = layer22_delta.dot(w12.T)\n",
    "    layer12_delta = layer12_error * sigmoid_deriv(layer12)    \n",
    "    w12 += layer12.T.dot(layer22_delta) * n\n",
    "    w02 += layer02.T.dot(layer12_delta) * n    \n",
    "    error = np.mean(np.abs(layer22_error))\n",
    "    accuracy = (1 - error) * 100\n",
    "print(\"Training Accuracy \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 44.27%\n"
     ]
    }
   ],
   "source": [
    "layer02 = x_test\n",
    "layer12 = sigmoid(np.dot(layer02, w02))\n",
    "layer22 = sigmoid(np.dot(layer12, w12))\n",
    "layer22_error = y_test - layer22\n",
    "error = np.mean(np.abs(layer22_error))\n",
    "accuracy = (1 - error) * 100\n",
    "\n",
    "print(\"Test Accuracy \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def normpdf(x, mean):\n",
    "    denom = (2*math.pi)\n",
    "    num = math.exp(-np.dot((x-mean),(x-mean))/2)\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static mixing of hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02153927930184863"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normpdf(np.array([1,-1]),m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 48.61%\n",
      "Test Accuracy with classifier 1: 50.88%\n",
      "Test Accuracy with classifier 2: 43.31%\n"
     ]
    }
   ],
   "source": [
    "layer0 = test\n",
    "layer1 = relu(np.dot(layer0, w0))\n",
    "layer2 = sigmoid(np.dot(layer1, w1))\n",
    "layer12 = sigmoid(np.dot(layer0, w02))\n",
    "layer22 = sigmoid(np.dot(layer12, w12))\n",
    "pred=0.7*layer2+0.3*layer22\n",
    "err1 = lab - layer2\n",
    "err2 = lab - layer22\n",
    "err = lab - pred\n",
    "error = np.mean(np.abs(err))\n",
    "accuracy = (1 - error) * 100\n",
    "\n",
    "print(\"Test Accuracy: \" + str(round(accuracy,2)) + \"%\")\n",
    "\n",
    "error = np.mean(np.abs(err1))\n",
    "accuracy = (1 - error) * 100\n",
    "print(\"Test Accuracy with classifier 1: \" + str(round(accuracy,2)) + \"%\")\n",
    "\n",
    "error = np.mean(np.abs(err2))\n",
    "accuracy = (1 - error) * 100\n",
    "print(\"Test Accuracy with classifier 2: \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic mixing of hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 50.53%\n"
     ]
    }
   ],
   "source": [
    "layer0 = test\n",
    "layer1 = relu(np.dot(layer0, w0))\n",
    "layer2 = sigmoid(np.dot(layer1, w1))\n",
    "layer12 = sigmoid(np.dot(layer0, w02))\n",
    "layer22 = sigmoid(np.dot(layer12, w12))\n",
    "pred = np.zeros(lab.shape)\n",
    "l=np.zeros((labels.shape[0],1))\n",
    "for i in range((len(l))):\n",
    "    j=np.max(np.array([normpdf(test[i,:],m1),normpdf(test[i,:],m2),normpdf(test[i,:],m3)]))\n",
    "    o=np.max(np.array([normpdf(test[i,:],m1),normpdf(test[i,:],m3),normpdf(test[i,:],m4)]))\n",
    "    l[i]=j/(j+o)\n",
    "    pred[i,:]=0.7*l[i]*layer2[i,:] + 0.3*(1-l[i])*layer22[i,:]\n",
    "err = lab - pred\n",
    "error = np.mean(np.abs(err))\n",
    "accuracy = (1 - error) * 100\n",
    "print(\"Test Accuracy: \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
